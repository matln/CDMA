#!/bin/bash

### Start 
. ./path.sh

# --------------------------------------------------------------------------------------------- #

voxceleb1_path=/data/corpus/VoxCeleb1_v2
voxceleb2_path=/data/corpus/VoxCeleb2
voices_path=/data/corpus/VOiCES/VOiCES_Box_unzip

feature="fbank_64"
conf="${SUBTOOLS}"/conf/sre-fbank-64.conf

[ ${feature##*_} == 'pitch' ] && pitch=true || pitch=false
feature_type=${feature%%_*}

seed=1024
nj=24

stage=0
endstage=7


# --------------------------------- dataset preparation ------------------------------- #
if [[ $stage -le 0 && 0 -le $endstage ]]; then
  # Prepare the data/voxceleb1_train, data/voxceleb2_train.
  local/make_voxceleb1_v2.pl $voxceleb1_path dev data/voxceleb1_train
  local/make_voxceleb2.pl $voxceleb2_path dev data/voxceleb2_train
  python local/make_voices.py --root-dir $voices_path --dataset dev
  python local/make_voices.py --root-dir $voices_path --dataset dev_label
  python local/make_voices.py --root-dir $voices_path --dataset eval

  # Combine trainset voxceleb1o2_train = voxceleb1_train + voxceleb2_train (without test part both)
  ${SUBTOOLS}/kaldi/utils/combine_data.sh data/voxceleb1o2_train data/voxceleb1_train data/voxceleb2_train

  # Get the copies of dataset which is labeled by a prefix like mfcc_23_pitch or fbank_40_pitch etc.
  ${SUBTOOLS}/newCopyData.sh --force false $feature "voxceleb1o2_train voices_dev voices_dev_label voices_eval"
fi

# -------------------------- extract training acoustic features ---------------------- #
if [[ $stage -le 1 && 1 -le $endstage ]]; then
  # out: feat.scp utt2num_frames utt2dur conf/mfcc.conf conf/pitch.conf
  ${SUBTOOLS}/makeFeatures.sh --pitch $pitch --nj $nj data/$feature/voxceleb1o2_train ${feature_type} ${conf}

  ${SUBTOOLS}/filterDataDir.sh --split-aug false data/$feature/voxceleb1o2_train data/voxceleb1_train/utt2spk \
    data/$feature/voxceleb1_train
fi

# -------------- extract acoustic features of the VOiCEs dataset ----------------- #
if [[ $stage -le 2 && 2 -le $endstage ]]; then
  # Make features for devset
  "${SUBTOOLS}"/makeFeatures.sh --pitch $pitch --nj $nj data/$feature/voices_dev ${feature_type} ${conf}
  "${SUBTOOLS}"/makeFeatures.sh --pitch $pitch --nj $nj data/$feature/voices_dev_label ${feature_type} ${conf}
  # Make features for eval set
  "${SUBTOOLS}"/makeFeatures.sh --pitch $pitch --nj $nj data/$feature/voices_eval ${feature_type} ${conf}
fi

# ---------------------------------- compute VAD -------------------------------------- #
if [[ $stage -le 3 && 3 -le $endstage ]]; then
  # Compute VAD for trainset
  "${SUBTOOLS}"/computeVad.sh --nj $nj data/$feature/voxceleb1o2_train "${SUBTOOLS}"/conf/vad-5.5.conf
  # Compute VAD for voices dev set
  "${SUBTOOLS}"/computeVad.sh --nj $nj data/$feature/voices_dev "${SUBTOOLS}"/conf/vad-5.5.conf
  "${SUBTOOLS}"/computeVad.sh --nj $nj data/$feature/voices_dev_label "${SUBTOOLS}"/conf/vad-5.5.conf
  # Compute VAD for voices eval set
  "${SUBTOOLS}"/computeVad.sh --nj $nj data/$feature/voices_eval "${SUBTOOLS}"/conf/vad-5.5.conf
fi

# ------------------------------ preprocess to generate chunks ------------------------- #
if [[ $stage -le 4 && 4 -le $endstage ]]; then
  # stage 0: vad-cmn, applies CMVN and removes nonspeech frames
  # stage 1: remove features that are too short after removing silence
  #   frames (200 frames), and throw out speakers with fewer than 8 utterances.
  # stage 2: get chunk egs

  # sample-type: trainset chunks sample type ( sequential | speaker_balance )
  #   speaker_balance: every speaker has the same number of chunks
  # chunk-num: -1:
  #   num_chunks_selected_of_every_speaker = int(total_chunks_of_all_speakers // num_spks) * scale) 
  # overlap: the overlap proportion of two adjacent chunks
  # valid-split-type: validation set split type (--default or --total-spk), class method "subset" in pytorch/libs/egs/kaldi_dataset.py
  # valid-num-utts: the number of utterances in validation set
  # valid-chunk-num: the number of chunks of every utterance in validation set
  # force_clear: Clear the dir generated by preprocess.
  # traindata
  # egs_dir: 在该目录下生成csv格式的chunk表单

  # features/preprocess_ssd is located on the SSD drive, (Symbolic link)
  chunk_size=400
  traindata=data/$feature/voxceleb1o2_train
  egs_dir=exp/egs/${feature}-voxceleb1o2_train-${chunk_size}-sequential-ssd

  "${SUBTOOLS}"/pytorch/pipeline/preprocess_to_egs.sh \
    --stage 0 --endstage 2 \
    --nj $nj --cmn true --limit-utts 8 --min-chunk 200 \
    --sample-type "sequential" --chunk_size ${chunk_size} --chunk-num -1 --scale 1.5 --overlap 0.1 \
    --drop-last-size 40 --valid-split-from-trainset true \
    --valid-split-type "--total-spk" --valid-num-utts 1024 --valid-chunk-num 2 \
    --force-clear true --seed ${seed} --compress true --suffix _nosil${chunk_size}_ssd --nosil true \
    --features_exp "features/preprocess_ssd" \
    ${traindata} ${egs_dir}

  "${SUBTOOLS}"/pytorch/pipeline/preprocess_to_egs.sh \
    --stage 0 --endstage 0 --nj $nj --cmn true --nosil false --force-clear true --compress true --suffix _cmn  \
    data/$feature/voxceleb1_train
fi


# ------------------------------------------------------------------------ #
# supervised domain adaptation
if [[ $stage -le 5 && 5 -le $endstage ]]; then
  chunk_size=400
  traindata=data/$feature/voices_dev_label
  egs_dir=exp/egs/${feature}-voices_dev_label-${chunk_size}-sequential-novad

  "${SUBTOOLS}"/pytorch/pipeline/preprocess_to_egs.sh \
    --stage 0 --endstage 2 \
    --nj $nj --cmn true --limit-utts 0 --min-chunk ${chunk_size} --remove_utts false \
    --sample-type "sequential" --chunk-size ${chunk_size} --chunk-num -1 --scale 1.5 --overlap 0.1 \
    --drop-last-size 199 --valid-split-from-trainset false \
    --force-clear true --seed ${seed} --compress false --suffix _cmn --nosil false \
    ${traindata} ${egs_dir}
  cp ${traindata}/trials ${traindata}_cmn/trials
fi

# ------------------------------------------------------------------------ #
# unsupervised domain adaptation
if [[ $stage -le 6 && 6 -le $endstage ]]; then
  chunk_size=400
  traindata=data/$feature/voices_dev
  egs_dir=exp/egs/${feature}-voices_dev-${chunk_size}-sequential-novad

  "${SUBTOOLS}"/pytorch/pipeline/preprocess_to_egs.sh \
    --stage 0 --endstage 2 --nj $nj --cmn true --remove_utts false \
    --sample-type "sequential" --chunk-size ${chunk_size} --chunk-num -1 --scale 1.5 --overlap 0 \
    --drop-last-size 199 --valid-split-from-trainset false \
    --force-clear true --seed ${seed} --compress false --suffix _cmn --nosil false \
    ${traindata} ${egs_dir}
  cp ${traindata}/trials ${traindata}_cmn/trials
fi

# ------------------------------ preprocess eval set ------------------------- #
evaldata=data/$feature/voices_eval

if [[ $stage -le 7 && 7 -le $endstage ]]; then
  "${SUBTOOLS}"/pytorch/pipeline/preprocess_to_egs.sh \
    --stage 0 --endstage 0 --nj $nj --cmn true --nosil false \
    --force-clear true --compress false --suffix _cmn \
    ${evaldata}
  cp ${evaldata}/trials ${evaldata}_cmn/trials
fi

